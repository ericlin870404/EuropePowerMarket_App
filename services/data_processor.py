# services/data_processor.py

from __future__ import annotations

import io
import xml.etree.ElementTree as ET
from datetime import datetime, date, timezone, timedelta
from typing import List, Tuple

import pandas as pd
from zoneinfo import ZoneInfo

from config.settings import SUPPORTED_COUNTRIES  # åªæ˜¯ç‚ºäº†æ–¹ä¾¿çŸ¥é“æœ‰å“ªäº›ä»£ç¢¼


# === æ™‚å€å°ç…§è¡¨ï¼šå’Œ data_fetcher è£¡çš„é‚è¼¯ä¿æŒä¸€è‡´ ===
TZ_BY_COUNTRY = {
    "FR": "Europe/Paris",
    "BE": "Europe/Brussels",
    "NL": "Europe/Amsterdam",
    "ES": "Europe/Madrid",
    "PT": "Europe/Lisbon",
    "IT-North": "Europe/Rome",
    "IT-South": "Europe/Rome",
    "GB": "Europe/London",
    "CZ": "Europe/Prague",
    "CH": "Europe/Zurich",
}


def _parse_utc_datetime(dt_str: str) -> datetime:
    """å°‡ '2025-01-05T23:00Z' ä¹‹é¡å­—ä¸²è½‰æˆ UTC datetimeã€‚"""
    s = dt_str.strip()
    if s.endswith("Z"):
        s = s[:-1]
        dt = datetime.fromisoformat(s)
        return dt.replace(tzinfo=timezone.utc)
    return datetime.fromisoformat(s).replace(tzinfo=timezone.utc)


def _get_timezone_for_country(country_code: str) -> ZoneInfo:
    tz_name = TZ_BY_COUNTRY.get(country_code, "UTC")
    return ZoneInfo(tz_name)


def _get_delivery_date(ts: ET.Element, country_code: str) -> date:
    """
    å¾å–®ä¸€ TimeSeries å–å¾—äº¤å‰²æ—¥ï¼ˆç•¶åœ°æ—¥æœŸï¼‰ï¼š
    timeInterval.start (UTC) â†’ è½‰ç•¶åœ°æ™‚å€ â†’ å–æ—¥æœŸã€‚
    """
    ns = ts.tag.split("}")[0].strip("{")

    period = ts.find(f"{{{ns}}}Period")
    if period is None:
        raise ValueError("TimeSeries ç¼ºå°‘ Period å…ƒç´ ã€‚")

    ti = period.find(f"{{{ns}}}timeInterval")
    if ti is None:
        raise ValueError("Period ç¼ºå°‘ timeInterval å…ƒç´ ã€‚")

    start_elem = ti.find(f"{{{ns}}}start")
    if start_elem is None or not (start_elem.text and start_elem.text.strip()):
        raise ValueError("timeInterval ç¼ºå°‘ startã€‚")

    utc_start = _parse_utc_datetime(start_elem.text)
    tz = _get_timezone_for_country(country_code)
    local_start = utc_start.astimezone(tz)
    return local_start.date()


def _resolution_to_expected_points(resolution: str) -> int:
    """
    å°‡ 'PT60M' ç­‰è§£ææˆä¸€å¤©æ‡‰æœ‰çš„é»æ•¸ã€‚
    ç›®å‰å‡è¨­ resolution çš†ç‚ºã€Œä»¥åˆ†é˜ç‚ºå–®ä½ã€ï¼š
    - PT60M â†’ 24
    - PT30M â†’ 48
    - PT15M â†’ 96
    è‹¥é‡åˆ°å…¶ä»–æ ¼å¼ï¼Œæœƒæ‹‹å‡ºéŒ¯èª¤ï¼Œä¹‹å¾Œå†è¦–æƒ…æ³æ“´å……ã€‚
    """
    res = resolution.strip().upper()
    if not res.startswith("PT") or not res.endswith("M"):
        raise ValueError(f"æš«ä¸æ”¯æ´çš„ resolution æ ¼å¼ï¼š{resolution}")

    minutes_str = res[2:-1]  # å»æ‰ 'PT' å’Œ 'M'
    try:
        minutes = int(minutes_str)
    except ValueError:
        raise ValueError(f"è§£æ resolution åˆ†é˜æ•¸å¤±æ•—ï¼š{resolution}")

    if minutes <= 0:
        raise ValueError(f"resolution åˆ†é˜æ•¸éœ€ > 0ï¼š{resolution}")

    # ä¸€å¤© 1440 åˆ†é˜
    expected = 1440 // minutes
    return expected


def _expand_points_with_fill(
    points: List[Tuple[int, float]],
    expected_points: int,
) -> List[Tuple[int, float]]:
    """
    æ ¹æ“š ENTSO-E çš„ã€Œç›¸åŒåƒ¹æ ¼çœç•¥å¾ŒçºŒé»ã€è¦å‰‡è£œå€¼ã€‚

    - points: å·²æŒ‰ position æ’åºå¥½çš„ (position, price) åˆ—è¡¨ã€‚
    - expected_points: ä¸€å¤©æ‡‰æœ‰çš„é»æ•¸ï¼ˆå¦‚ 24 / 48 / 96ï¼‰ã€‚

    è¦å‰‡ï¼š
    - è‹¥ position æœ‰è·³è™Ÿï¼Œä¾‹å¦‚ 4 â†’ 6ï¼Œå‰‡è£œä¸Š 5ï¼Œåƒ¹æ ¼ = position 4 çš„åƒ¹æ ¼ã€‚
    - è‹¥æœ€å¾Œä¸€ç­† position < expected_pointsï¼Œä¾‹å¦‚ 23/24ï¼Œå‰‡ 24 çš„åƒ¹æ ¼ = position 23 çš„åƒ¹æ ¼ã€‚
    """
    if not points:
        return []

    points = sorted(points, key=lambda x: x[0])
    expanded: List[Tuple[int, float]] = []

    prev_pos, prev_price = points[0]
    if prev_pos != 1:
        # ç†è«–ä¸Šç¬¬ä¸€å€‹ position æ‡‰ç‚º 1ï¼Œè‹¥ä¸æ˜¯å°±å ±éŒ¯ï¼Œé¿å…äº‚å¡«ã€‚
        raise ValueError(f"ç¬¬ä¸€å€‹ position ä¸æ˜¯ 1ï¼Œè€Œæ˜¯ {prev_pos}ï¼Œè³‡æ–™æ ¼å¼å¯èƒ½ç•°å¸¸ã€‚")

    expanded.append((prev_pos, prev_price))

    for pos, price in points[1:]:
        if pos <= prev_pos:
            # ééå¢ä»£è¡¨è³‡æ–™æœ‰å•é¡Œï¼Œå…ˆè·³éæˆ– raiseï¼›é€™è£¡é¸æ“‡ raise è®“å•é¡Œæµ®ç¾
            raise ValueError(f"position ééå¢ï¼š{prev_pos} â†’ {pos}")

        # è‹¥ä¸­é–“æœ‰ç¼ºå€¼ï¼Œä¾‹å¦‚ prev_pos=4, pos=6ï¼Œå‰‡è£œä¸Š 5
        if pos > prev_pos + 1:
            for missing_pos in range(prev_pos + 1, pos):
                expanded.append((missing_pos, prev_price))

        expanded.append((pos, price))
        prev_pos, prev_price = pos, price

    # è‹¥æœ€å¾Œä¸€ç­† position é‚„æ²’åˆ° expected_pointsï¼Œè£œåˆ°å°¾ç«¯
    if prev_pos < expected_points:
        for missing_pos in range(prev_pos + 1, expected_points + 1):
            expanded.append((missing_pos, prev_price))

    # è‹¥å¯¦éš›æ¯” expected é‚„å¤šï¼Œä¹Ÿå…ˆä¿ç•™ä½†æé†’ä¸€ä¸‹
    # ï¼ˆå¯¦å‹™ä¸Šä¸å¤ªå¯èƒ½ç™¼ç”Ÿï¼Œè‹¥ç™¼ç”Ÿä»£è¡¨ resolution è¨ˆç®—é‚è¼¯è¦æª¢æŸ¥ï¼‰
    if prev_pos > expected_points:
        print(
            f"[è­¦å‘Š] æ­¤ TimeSeries æœ€å¾Œ position={prev_pos}ï¼Œ"
            f"å¤§æ–¼é æœŸ {expected_points}ï¼Œè«‹æª¢æŸ¥ resolution é…ç½®ã€‚"
        )

    return expanded

def _is_last_sunday_of_mar_or_oct(date_str: str) -> bool:
    """
    åˆ¤æ–·çµ¦å®šæ—¥æœŸï¼ˆå­—ä¸²æ ¼å¼ YYYY/MM/DDï¼‰æ˜¯å¦ç‚ºï¼š
    - 3 æœˆæœ€å¾Œä¸€å€‹æ˜ŸæœŸæ—¥ï¼Œæˆ–
    - 10 æœˆæœ€å¾Œä¸€å€‹æ˜ŸæœŸæ—¥

    è¨»ï¼šé€™è£¡åªç”¨ä¾†ç²—ç•¥ç•¥é DST åˆ‡æ›æ—¥ï¼Œä¸åšåš´æ ¼æ›†æ³•è™•ç†ã€‚
    """
    dt = datetime.strptime(date_str, "%Y/%m/%d").date()

    # åªé—œå¿ƒ 3 æœˆèˆ‡ 10 æœˆ
    if dt.month not in (3, 10):
        return False

    # Python çš„ weekday(): é€±ä¸€=0, é€±æ—¥=6
    if dt.weekday() != 6:  # ä¸æ˜¯æ˜ŸæœŸæ—¥
        return False

    # åˆ¤æ–·æ˜¯å¦æ˜¯ã€Œé€™å€‹æœˆçš„æœ€å¾Œä¸€å€‹æ˜ŸæœŸæ—¥ã€ï¼š
    # è‹¥å†åŠ  7 å¤©å·²ç¶“è·¨åˆ°ä¸‹ä¸€å€‹æœˆä»½ï¼Œå°±ä»£è¡¨å®ƒæ˜¯æœ€å¾Œä¸€å€‹æ˜ŸæœŸæ—¥
    return (dt + timedelta(days=7)).month != dt.month

def parse_da_xml_to_raw_csv_bytes(
    xml_bytes: bytes,
    country_code: str,
) -> bytes:
    """
    å°‡æ—¥å‰é›»åƒ¹ XML è§£æç‚ºã€ŒåŸå§‹ã€CSVï¼š

    æ¬„ä½ï¼š
    - Date: äº¤å‰²æ—¥ï¼ˆç•¶åœ°æ—¥æœŸï¼Œæ ¼å¼ YYYY/MM/DDï¼‰
    - Market Time Unit (MTU): positionï¼ˆè£œå€¼å¾Œ 1..Nï¼‰
    - Day-ahead Price (EUR/MWh): å°æ‡‰åƒ¹æ ¼ï¼Œä¾ ENTSO-E è¦å‰‡è£œå€¼

    é¡å¤–è¦å‰‡ï¼š
    - è‹¥ TimeSeries ä¸­å­˜åœ¨
      <classificationSequence_AttributeInstanceComponent.position>
      å‰‡è¦–ç‚ºç‰¹æ®Šåºåˆ—ï¼ˆé™„åŠ ç”¢å“æˆ–åˆ†æ®µï¼‰ï¼Œæ•´æ¢ TimeSeries ç›´æ¥ç•¥éï¼Œ
      åƒ…ä¿ç•™æœªæ¨™è¨» classificationSequence çš„ã€ŒåŸºæœ¬åƒ¹æ ¼ã€TimeSeriesã€‚
    """
    root = ET.fromstring(xml_bytes)
    ns = root.tag.split("}")[0].strip("{")

    rows = []

    for ts in root.findall(f".//{{{ns}}}TimeSeries"):

        # === (1) classificationSequence éæ¿¾ ===
        cls_elem = ts.find(
            f"{{{ns}}}classificationSequence_AttributeInstanceComponent.position"
        )
        if cls_elem is not None and cls_elem.text and cls_elem.text.strip():
            cls_val = cls_elem.text.strip()
            print(
                "[åˆ†é¡åºè™Ÿ] è·³é TimeSeriesï¼š"
                f"classificationSequence_AttributeInstanceComponent.position = {cls_val}"
            )
            continue

        # === (2) æ­£å¸¸è§£ææµç¨‹ ===
        delivery_day = _get_delivery_date(ts, country_code)

        period = ts.find(f"{{{ns}}}Period")
        if period is None:
            continue

        res_elem = period.find(f"{{{ns}}}resolution")
        if res_elem is None or not (res_elem.text and res_elem.text.strip()):
            raise ValueError("Period ç¼ºå°‘ resolutionã€‚")

        resolution_str = res_elem.text.strip()
        expected_points = _resolution_to_expected_points(resolution_str)

        # æ”¶é›†åŸå§‹ Point
        raw_points: List[Tuple[int, float]] = []
        for pt in period.findall(f"{{{ns}}}Point"):
            pos_elem = pt.find(f"{{{ns}}}position")
            price_elem = pt.find(f"{{{ns}}}price.amount")

            if (
                pos_elem is None
                or not (pos_elem.text and pos_elem.text.strip())
                or price_elem is None
                or not (price_elem.text and price_elem.text.strip())
            ):
                continue

            pos = int(pos_elem.text.strip())
            price = float(price_elem.text.strip())
            raw_points.append((pos, price))

        if not raw_points:
            print("[è­¦å‘Š] æŸä¸€å€‹ TimeSeries å®Œå…¨æ²’æœ‰ Pointï¼Œå·²ç•¥éã€‚")
            continue

        # ä¾ ENTSO-E è¦å‰‡è£œè¶³ç¼ºæ¼ position
        expanded_points = _expand_points_with_fill(raw_points, expected_points)

        date_str = delivery_day.strftime("%Y/%m/%d")

        for pos, price in expanded_points:
            rows.append(
                {
                    "Date": date_str,
                    "Market Time Unit (MTU)": pos,
                    "Day-ahead Price (EUR/MWh)": price,
                }
            )

    if not rows:
        raise ValueError("è§£æå¾Œæ²’æœ‰ä»»ä½•è³‡æ–™ï¼Œè«‹æª¢æŸ¥ XML å…§å®¹ã€‚")

    df = pd.DataFrame(rows)
    df.sort_values(by=["Date", "Market Time Unit (MTU)"], inplace=True)

    buf = io.StringIO()
    df.to_csv(buf, index=False)
    csv_bytes = buf.getvalue().encode("utf-8")

    return csv_bytes

def convert_raw_mtu_csv_to_hourly_csv_bytes(raw_csv_bytes: bytes) -> bytes:
    """
    å°‡ã€ŒåŸå§‹ MTU CSVã€è½‰æ›ç‚ºã€Œæ¯å°æ™‚ã€CSVã€‚

    è¼¸å…¥ CSV æ¬„ä½ï¼ˆå·²ç”± parse_da_xml_to_raw_csv_bytes ç”¢ç”Ÿï¼‰ï¼š
    - Date
    - Market Time Unit (MTU)
    - Day-ahead Price (EUR/MWh)

    è¼¸å‡º CSV æ¬„ä½ï¼š
    - Date
    - Hour  (1..24)
    - Day-ahead Price (EUR/MWh)

    è¦å‰‡ï¼š
    - è‹¥æŸæ—¥ MTU æ•¸é‡ç‚º 24  â†’ è¦–ç‚º 60 åˆ†é˜è§£æåº¦ï¼Œåƒ¹æ ¼ç›´æ¥æ²¿ç”¨ï¼ˆHour = MTUï¼‰ã€‚
    - è‹¥æŸæ—¥ MTU æ•¸é‡ç‚º 48  â†’ è¦–ç‚º 30 åˆ†é˜è§£æåº¦ï¼Œæ¯ 2 å€‹ MTU å¹³å‡ç‚º 1 å°æ™‚ã€‚
    - è‹¥æŸæ—¥ MTU æ•¸é‡ç‚º 96  â†’ è¦–ç‚º 15 åˆ†é˜è§£æåº¦ï¼Œæ¯ 4 å€‹ MTU å¹³å‡ç‚º 1 å°æ™‚ã€‚
    """
    # è®€å…¥åŸå§‹ CSV
    buf = io.StringIO(raw_csv_bytes.decode("utf-8"))
    df = pd.read_csv(buf)

    required_cols = {
        "Date",
        "Market Time Unit (MTU)",
        "Day-ahead Price (EUR/MWh)",
    }
    if not required_cols.issubset(df.columns):
        raise ValueError(
            f"åŸå§‹ CSV æ¬„ä½ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{required_cols - set(df.columns)}"
        )

    df = df.copy()
    df.sort_values(by=["Date", "Market Time Unit (MTU)"], inplace=True)

    all_hourly_rows = []

    # é€æ—¥è™•ç†
    for date_value, df_day in df.groupby("Date"):

        # ğŸ”¸ å…ˆæª¢æŸ¥æ˜¯å¦ç‚º 3 æœˆ / 10 æœˆçš„æœ€å¾Œä¸€å€‹æ˜ŸæœŸæ—¥ï¼ˆæ¨å®šç‚º DST åˆ‡æ›æ—¥ï¼‰
        if _is_last_sunday_of_mar_or_oct(date_value):
            print(f"[DST] åµæ¸¬åˆ°å¤ä»¤/å†¬ä»¤åˆ‡æ›æ—¥ {date_value}ï¼Œæš«æ™‚è·³éæ­¤æ—¥çš„æ¯å°æ™‚è½‰æ›ã€‚")
            continue
        
        df_day = df_day.copy()
        n_points = len(df_day)

        if n_points == 24:
            # 60 åˆ†é˜è§£æåº¦ï¼šä¸€å€‹ MTU å°æ‡‰ä¸€å€‹å°æ™‚ï¼Œåƒ¹æ ¼ç›´æ¥æ²¿ç”¨
            df_day["Hour"] = df_day["Market Time Unit (MTU)"].astype(int)
            hourly = df_day[["Hour", "Day-ahead Price (EUR/MWh)"]].copy()
        elif n_points == 48:
            # 30 åˆ†é˜è§£æåº¦ï¼šæ¯ 2 å€‹ MTU å¹³å‡æˆ 1 å°æ™‚
            df_day["Hour"] = (df_day["Market Time Unit (MTU)"].astype(int) - 1) // 2 + 1
            hourly = (
                df_day.groupby("Hour", as_index=False)["Day-ahead Price (EUR/MWh)"]
                .mean()
            )
        elif n_points == 96:
            # 15 åˆ†é˜è§£æåº¦ï¼šæ¯ 4 å€‹ MTU å¹³å‡æˆ 1 å°æ™‚
            df_day["Hour"] = (df_day["Market Time Unit (MTU)"].astype(int) - 1) // 4 + 1
            hourly = (
                df_day.groupby("Hour", as_index=False)["Day-ahead Price (EUR/MWh)"]
                .mean()
            )
        else:
            # å…¶ä»–æƒ…æ³ä»£è¡¨è³‡æ–™æ ¼å¼ä¸åœ¨é æœŸç¯„åœï¼Œå…ˆæ˜ç¢ºæ‹‹éŒ¯è®“å•é¡Œæµ®ç¾
            raise ValueError(
                f"æ—¥æœŸ {date_value} çš„ MTU ç­†æ•¸ç‚º {n_points}ï¼Œ"
                "ç›®å‰åƒ…æ”¯æ´ 24 / 48 / 96 ç­†å°æ‡‰ 60 / 30 / 15 åˆ†é˜è§£æåº¦ã€‚"
            )

        hourly.sort_values(by="Hour", inplace=True)

        # è£œä¸Š Date æ¬„ä½
        hourly.insert(0, "Date", date_value)

        all_hourly_rows.append(hourly)

    if not all_hourly_rows:
        raise ValueError("è½‰æ›å¾Œæ²’æœ‰ä»»ä½•è³‡æ–™ï¼Œè«‹æª¢æŸ¥åŸå§‹ CSVã€‚")

    df_hourly = pd.concat(all_hourly_rows, ignore_index=True)

    # æ¬„ä½é †åºèª¿æ•´ç‚ºæŒ‡å®šæ ¼å¼
    df_hourly = df_hourly[["Date", "Hour", "Day-ahead Price (EUR/MWh)"]]

    # è½‰å› CSV bytes
    out_buf = io.StringIO()
    df_hourly.to_csv(out_buf, index=False)
    hourly_csv_bytes = out_buf.getvalue().encode("utf-8")

    return hourly_csv_bytes
